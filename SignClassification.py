# -*- coding: utf-8 -*-
"""SignClassificationGroup1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FvjAlmT5Iqx6FK1cG8XCjbiA-c4I0OAs
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import os
import time

# mount googledrive
from google.colab import drive

drive.mount('/content/gdrive', force_remount=True)

# Path to Dataset
master_path = '/content/drive/My Drive/utraFriends/arrowDataset'


# Helper Functions
def get_relevant_indices(dataset, classes, target_classes):
    indices = []
    for i in range(len(dataset)):
        # Check if the label is in the target classes
        label_index = dataset[i][1]  # ex: 3
        label_class = classes[label_index]  # ex: 'cat'
        if label_class in target_classes:
            indices.append(i)
    return indices


def get_data_loader(target_classes, batch_size):
    transform = transforms.Compose([transforms.Resize((200, 200), interpolation=2),
                                    transforms.ToTensor()])

    # classes are folders in each directory with these names
    classes = ['rightArrow', 'leftArrow', 'upArrow']

    # Creating the entire Training Dataset
    trainset = torchvision.datasets.ImageFolder(master_path, transform=transform)

    # Getting the indices for training set inorder to split to validation and training
    relevant_indices = get_relevant_indices(trainset, classes, target_classes)

    # Split into train and validation
    np.random.seed(1000)
    np.random.shuffle(relevant_indices)
    split = int(len(relevant_indices) * 0.70)  # split at 70%

    # split into train and validation indices
    relevant_train_indices, relevant_val_indices = relevant_indices[:split], relevant_indices[split:]
    train_sampler = SubsetRandomSampler(relevant_train_indices)
    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                               num_workers=1, sampler=train_sampler)
    val_sampler = SubsetRandomSampler(relevant_val_indices)
    val_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                             num_workers=1, sampler=val_sampler)

    return train_loader, val_loader, classes


from google.colab import drive

drive.mount('/content/drive')

train_loader, val_loader, classes = get_data_loader(target_classes=['rightArrow', 'leftArrow', 'upArrow'], batch_size=1)

k = 0
for images, labels in train_loader:
    # since batch_size = 1, there is only 1 image in `images`
    image = images[0]
    # place the colour channel at the end, instead of at the beginning
    img = np.transpose(image, [1, 2, 0])
    # normalize pixel intensity values to [0, 1]
    img = img / 2 + 0.5
    plt.subplot(3, 5, k + 1)
    plt.axis('off')
    plt.imshow(img)

    k += 1
    if k > 14:
        break

import torch
import torch.nn as nn
import torch.nn.functional as F

import matplotlib.pyplot as plt  # for plotting
import torch.optim as optim  # for gradient descent

torch.manual_seed(1)  # set the random seed


class CNNClassifier(nn.Module):
    def __init__(self):
        super(CNNClassifier, self).__init__()
        self.name = "Class"
        self.conv1 = nn.Conv2d(3, 5, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(5, 10, 5)
        self.fc1 = nn.Linear(10 * 47 * 47, 220)
        self.fc2 = nn.Linear(220, 3)

    def forward(self, img):
        x = self.pool(F.relu(self.conv1(img)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 10 * 47 * 47)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x


def train(model, train_loader, val_loader, batch_size=27, num_epochs=5, learn_rate=0.001):
    torch.manual_seed(1000)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learn_rate)

    iters, train_acc, val_acc = [], [], []

    # training
    print("Training Started...")
    n = 0  # the number of iterations
    start_time = time.time()
    for epoch in range(num_epochs):
        for imgs, labels in iter(train_loader):

            if use_cuda and torch.cuda.is_available():
                imgs = imgs.cuda()
                labels = labels.cuda()

            out = model(imgs)  # forward pass
            loss = criterion(out, labels)  # compute the total loss
            loss.backward()  # backward pass (compute parameter updates)
            optimizer.step()  # make the updates for each parameter
            optimizer.zero_grad()  # a clean up step for PyTorch
            n += 1

        # track accuracy
        iters.append(n)
        train_acc.append(get_accuracy(model, train_loader))
        val_acc.append(get_accuracy(model, val_loader))
        print(epoch, train_acc[-1], val_acc[-1])
    end_time = time.time()

    plt.title("Training Curve")
    plt.plot(iters, train_acc, label="Training")
    plt.plot(iters, val_acc, label="Validation")
    plt.xlabel("Iterations")
    plt.ylabel("Validation Accuracy")
    plt.legend(loc='best')
    plt.show()
    return train_acc, val_acc


def get_accuracy(model, data_loader):
    correct = 0
    total = 0
    for imgs, labels in data_loader:

        if use_cuda and torch.cuda.is_available():
            imgs = imgs.cuda()
            labels = labels.cuda()

        output = model(imgs)
        # select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total


# Training Curve
def plot_training_curve(path):
    """ Plots the training curve for a model run, given the csv files
    containing the train/validation error/loss.

    Args:
        path: The base path of the csv files produced during training
    """
    import matplotlib.pyplot as plt
    train_acc = np.loadtxt("{}_train_acc.csv".format(path))
    val_acc = np.loadtxt("{}_val_acc.csv".format(path))
    plt.title("Train vs Validation Accuracy")
    n = len(train_acc)  # number of epochs
    plt.plot(range(1, n + 1), train_acc, label="Train")
    plt.plot(range(1, n + 1), val_acc, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend(loc='best')
    plt.show()


use_cuda = True
train(CNNClassifier(), train_loader, val_loader, batch_size=1, num_epochs=10, learn_rate=0.00025)
